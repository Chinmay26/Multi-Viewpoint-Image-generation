{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import os\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "print \"loading data\"\n",
    "#iterate over directory and get all png images\\n\n",
    "imageset = np.zeros((7704,64,64,3))\n",
    "\n",
    "#There are 7704 images in the dataset.\n",
    "#214 folders. Each having 36 images.\n",
    "rootdir = '/home/chsarath/kaushal_project/mug/models/3dw'\n",
    "cnt = 0\n",
    "total_cnt = 0\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        filepath = subdir + os.sep + file\n",
    "        if filepath.endswith('.png'):\n",
    "            if cnt == 36:\n",
    "                cnt = 0\n",
    "                total_cnt += 1\n",
    "            cnt += 1\n",
    "            seq_number = int(filepath.split('-')[-1].split('.')[0])\n",
    "            imageset[total_cnt*36 + seq_number] = scipy.misc.imread(filepath)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "tmp = imageset[115][...,::-1]\n",
    "plt.switch_backend('agg')\n",
    "plt.imshow(tmp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#defination of my layers\n",
    "\n",
    "def conv2d(input, kernel_size, stride, num_filter):\n",
    "    stride_shape = [1, stride, stride, 1]\n",
    "    filter_shape = [kernel_size, kernel_size, input.get_shape()[3], num_filter]\n",
    "\n",
    "    W = tf.get_variable('w', filter_shape, tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "    b = tf.get_variable('b', [1, 1, 1, num_filter], initializer=tf.constant_initializer(0.0))\n",
    "    return tf.nn.conv2d(input, W, stride_shape, padding='SAME') + b\n",
    "\n",
    "def max_pool(input, kernel_size, stride):\n",
    "    ksize = [1, kernel_size, kernel_size, 1]\n",
    "    strides = [1, stride, stride, 1]\n",
    "    return tf.nn.max_pool(input, ksize=ksize, strides=strides, padding='SAME')\n",
    "\n",
    "def deconv2d(input, kernel_size, stride, num_filter):\n",
    "    filter_shape = [kernel_size, kernel_size, num_filter, input.get_shape[3]]\n",
    "    out_shape = [input.get_shape[0], input.get_shape[1]*2, input.get_shape[1]*2, num_filter]\n",
    "    stride_shape = [1, stride, stride, 1]\n",
    "    W = tf.get_variable('w', filter_shape, tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "    \n",
    "    return tf.nn.conv2d_transpose(input, W, out_shape, stride_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Network Parameters\n",
    "\n",
    "#Encoder\n",
    "# input is 64 * 64 * 3 \n",
    "# batch_size is 256\n",
    "\n",
    "\n",
    "# tf Graph input (only pictures)\n",
    "\n",
    "inputs_ = tf.placeholder(tf.float32, (None, 64,64,3), name=\"input\")\n",
    "targets_ = tf.placeholder(tf.float32, (None, 64,64,3), name=\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Building the encoder\n",
    "#Layer Architecture\n",
    "# Encoder will have Conv + relu + Max pool + Conv + relu  + Max pool + Conv + relu  + Max pool\n",
    "# After 3 Convolution ,we will have a latent space\n",
    "\n",
    "with tf.variable_scope('conv1'):\n",
    "    conv1 = conv2d(inputs_, 7, 1, 32)\n",
    "    relu1 = tf.nn.relu(conv1)\n",
    "    pool1 = max_pool(relu1, 3, 2)\n",
    "\n",
    "# Size of pool1 would be 32*32*32\n",
    "\n",
    "with tf.variable_scope('conv2'):\n",
    "    conv2 = conv2d(pool1, 5, 1, 16)\n",
    "    relu2 = tf.nn.relu(conv2)\n",
    "    pool2 = max_pool(relu2, 3, 2)\n",
    "    \n",
    "# Size of pool2 would be 16*16*16\n",
    "\n",
    "with tf.variable_scope('conv3'):\n",
    "    conv3 = conv2d(pool2, 3, 1, 8)\n",
    "    relu3 = tf.nn.relu(conv3)\n",
    "    pool3 = max_pool(relu3, 3, 2)\n",
    "\n",
    "# Latent space is 8*8*8\n",
    "\n",
    "#Building the decoder\n",
    "\n",
    "with tf.variable_scope('deconv1'):\n",
    "    deconv1 = deconv2d(pool3, 3, 1, 16)\n",
    "    relu4 = tf.nn.relu(deconv1)\n",
    "\n",
    "with tf.variable_scope('deconv2'):\n",
    "    deconv2 = deconv2d(deconv1, 5, 1, 32)\n",
    "    relu5 = tf.nn.relu(deconv2)\n",
    "\n",
    "with tf.variable_scope('deconv3'):\n",
    "    deconv3 = deconv2d(deconv2, 7, 1, 64)\n",
    "    relu6 = tf.nn.relu(deconv3)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#calculate loss\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = labels, logits = logits))\n",
    "\n",
    "#Optimizer\n",
    "global_step = tf.Variable(0,trainable=False)\n",
    "lr = tf.train.exponential_decay(5e-4, global_step, 1000, 0.96, staircase=True)\n",
    "optimizer = tf.train.AdamOptimizer(lr)\n",
    "train_op = optimizer.minimize(loss=loss_op)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Training Parameters\n",
    "\n",
    "epoch = 20\n",
    "batch_size = 100\n",
    "\n",
    "display_step = 1000\n",
    "examples_to_show = 10\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
