{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import misc\n",
    "from scipy import ndimage\n",
    "import os\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.utils import shuffle\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#normalize data\n",
    "def normalize(data):\n",
    "    data *= 2\n",
    "    data /= 255\n",
    "    data -= 1\n",
    "    return data\n",
    " \n",
    "#denormalize data\n",
    "def denormalize(data):\n",
    "    data += 1\n",
    "    data *=  255\n",
    "    data /= 2\n",
    "    return data\n",
    "\n",
    "def get_batch(batch_number, dir_name):\n",
    "    cur_batch_dir = dir_name + '/batch_' + str(batch_number)\n",
    "    data_ = np.load(cur_batch_dir+'data.npy')\n",
    "    label_ = np.load(cur_batch_dir+'label.npy')\n",
    "    pose_ = np.load(cur_batch_dir+'pose.npy')\n",
    "    data_ = normalize(data_)\n",
    "    label_ = normalize(label_)\n",
    "    return data_, label_, pose_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "#to Reset Tensor Flow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#defination of my layers\n",
    "'''\n",
    "def conv2d(input, kernel_size, stride, num_filter):\n",
    "    stride_shape = [1, stride, stride, 1]\n",
    "    filter_shape = [kernel_size, kernel_size, input.get_shape()[3], num_filter]\n",
    "\n",
    "    W = tf.get_variable('w', filter_shape, tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "    b = tf.get_variable('b', [1, 1, 1, num_filter], initializer=tf.constant_initializer(0.0))\n",
    "    return tf.nn.conv2d(input, W, stride_shape, padding='SAME') + b\n",
    "'''\n",
    "def conv2d(input, kernel_size, stride, num_filter, name = 'conv2d'):\n",
    "    with tf.variable_scope(name):\n",
    "        stride_shape = [1, stride, stride, 1]\n",
    "        filter_shape = [kernel_size, kernel_size, input.get_shape()[3], num_filter]\n",
    "\n",
    "        W = tf.get_variable('w', filter_shape, tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "        b = tf.get_variable('b', [1, 1, 1, num_filter], initializer = tf.constant_initializer(0.0))\n",
    "        return tf.nn.conv2d(input, W, stride_shape, padding = 'SAME') + b\n",
    "\n",
    "def max_pool(input, kernel_size, stride):\n",
    "    ksize = [1, kernel_size, kernel_size, 1]\n",
    "    strides = [1, stride, stride, 1]\n",
    "    return tf.nn.max_pool(input, ksize=ksize, strides=strides, padding='SAME')\n",
    "\n",
    "def deconv2d(input, kernel_size, stride, num_filter):\n",
    "    filter_shape = [kernel_size, kernel_size, num_filter, input.get_shape()[3]]\n",
    "    # tf.constant([input.get_shape()[0], input.get_shape()[1]*2, input.get_shape()[1]*2, num_filter], tf.int32)\n",
    "    input_dim = input.get_shape().as_list()\n",
    "    batch_size = input_dim[0]\n",
    "    w = input_dim[1]\n",
    "    out_shape = tf.stack([batch_size, w*2, w*2, num_filter])    \n",
    "    b = tf.get_variable('b', [1, 1, 1, num_filter], initializer = tf.constant_initializer(0.0))\n",
    "    stride_shape = [1, stride, stride, 1]\n",
    "    W = tf.get_variable('w', filter_shape, tf.float32, tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    return tf.nn.conv2d_transpose(input, W, out_shape, stride_shape) + b\n",
    "\n",
    "def conv2d_transpose(input, kernel_size, stride, num_filter, name = 'conv2d_transpose'):\n",
    "    with tf.variable_scope(name):\n",
    "        stride_shape = [1, stride, stride, 1]\n",
    "        filter_shape = [kernel_size, kernel_size, num_filter, input.get_shape()[3]]\n",
    "        output_shape = tf.stack([tf.shape(input)[0], tf.shape(input)[1] * 2, tf.shape(input)[2] * 2, num_filter])\n",
    "\n",
    "        W = tf.get_variable('w', filter_shape, tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "        b = tf.get_variable('b', [1, 1, 1, num_filter], initializer = tf.constant_initializer(0.0))\n",
    "        return tf.nn.conv2d_transpose(input, W, output_shape, stride_shape, padding = 'SAME') + b\n",
    "\n",
    "\n",
    "def batch_norm(input, is_training):\n",
    "    out = tf.contrib.layers.batch_norm(input, decay = 0.99, center = True, scale = True,\n",
    "                                       is_training = is_training, updates_collections = None)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class AutoEncoder(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.inputs_ = tf.placeholder(tf.float32, [None, 64, 64, 3])\n",
    "        self.targets_ = tf.placeholder(tf.float32, [None, 64, 64, 3])\n",
    "        self.pose_ = tf.placeholder(tf.float32, [None, 8, 8, 36])\n",
    "        self.is_train = tf.placeholder(tf.bool)\n",
    "        self.num_epoch = 100\n",
    "        self.batch_size = 25\n",
    "        self._build_model()\n",
    "        \n",
    "    def _encoder_decoder(self):\n",
    "        with tf.variable_scope('conv1'):\n",
    "            _ = conv2d(self.inputs_, 3, 2, 16, 'conv1')\n",
    "            #_ = batch_norm(_, self.is_train)\n",
    "            _ = tf.nn.relu(_)\n",
    "            _ = conv2d(_, 3, 2, 32, 'conv2')\n",
    "            #_ = batch_norm(_, self.is_train)\n",
    "            _ = tf.nn.relu(_)\n",
    "            #_ = conv2d(_, 3, 2, 64, 'conv3')\n",
    "            #_ = tf.nn.relu(_)\n",
    "            _ = conv2d(_, 3, 2, 64, 'conv4')\n",
    "            _ = tf.nn.relu(_)\n",
    "            _ = tf.concat([_, self.pose_], 3)\n",
    "            #_ = conv2d_transpose(_, 3, 2, 64, 'deconv0')\n",
    "            #_ = tf.nn.relu(_)\n",
    "            _ = conv2d_transpose(_, 3, 2, 32, 'deconv1')\n",
    "            #_ = batch_norm(_, self.is_train)\n",
    "            _ = tf.nn.relu(_)\n",
    "            _ = conv2d_transpose(_, 3, 2, 16, 'deconv2')\n",
    "            #_ = batch_norm(_, self.is_train)\n",
    "            _ = tf.nn.relu(_)\n",
    "            _ = conv2d_transpose(_, 3, 2, 3, 'deconv3')\n",
    "            _ = tf.nn.tanh(_)\n",
    "            return _\n",
    "\n",
    "    def _loss(self, labels, logits):\n",
    "        self.loss_op = tf.reduce_mean(abs(labels - logits))\n",
    "    \n",
    "    def _build_optimizer(self):\n",
    "        global_step = tf.Variable(0,trainable=False)\n",
    "        lr = tf.train.exponential_decay(5e-4, global_step, 1000, 0.96, staircase=True)\n",
    "        optimizer = tf.train.AdamOptimizer(lr)\n",
    "        self.train_op = optimizer.minimize(loss=self.loss_op)\n",
    "\n",
    "    def _build_model(self):\n",
    "        self.out = self._encoder_decoder()\n",
    "        self._loss(self.out, self.targets_)\n",
    "        self._build_optimizer()\n",
    "        \n",
    "    def train(self, sess, dir_name):\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print('-' * 5 + '  Start training  ' + '-' * 5)\n",
    "        for e in range(self.num_epoch):\n",
    "            for i in range(1,51):\n",
    "                X_train, Y_train, pose = get_batch(i, dir_name)\n",
    "                for ii in range(X_train.shape[0] // self.batch_size):\n",
    "                    batch = X_train[ii*self.batch_size : (ii+1)*self.batch_size]\n",
    "                    batch_labels = Y_train[ii*self.batch_size : (ii+1)*self.batch_size]\n",
    "                    pose_labels = pose[ii*self.batch_size : (ii+1)*self.batch_size]\n",
    "                    feed_dict = {self.inputs_: batch, self.targets_: batch_labels, self.pose_:pose_labels, self.is_train:True}\n",
    "                    fetches = [self.train_op, self.loss_op]\n",
    "                    _, loss = sess.run(fetches, feed_dict=feed_dict)\n",
    "        print(\"Epoch: {}/{}...\".format(e+1, self.num_epoch),\n",
    "            \"Training loss: {:.4f}\".format(loss))\n",
    "    \n",
    "    def evaluate(self, sess, X_eval, Y_eval, pose_eval):\n",
    "        out = np.zeros(Y_eval.shape)\n",
    "        for ii in range(X_eval.shape[0] // self.batch_size):\n",
    "            batch = X_eval[ii*self.batch_size : (ii+1)*self.batch_size]\n",
    "            batch_labels = Y_eval[ii*self.batch_size : (ii+1)*self.batch_size]\n",
    "            pose_labels = pose_eval[ii*self.batch_size : (ii+1)*self.batch_size]\n",
    "            feed_dict = {self.inputs_: batch, self.targets_: batch_labels, self.pose_:pose_labels, self.is_train:False}\n",
    "            fetches = [self.train_op, self.loss_op, self.out]\n",
    "            _, loss, out[ii*self.batch_size : (ii+1)*self.batch_size] = sess.run(fetches, feed_dict=feed_dict)\n",
    "            print (\"loss: {:.4f}\".format(loss))\n",
    "        return denormalize(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "data_dir = \"/home/chsarath/kaushal_project/car_\"\n",
    "# Train our sample model\n",
    "with tf.Session() as sess:\n",
    "    #with tf.device('/device:gpu:0'):\n",
    "    model = AutoEncoder()\n",
    "    model.train(sess, data_dir)\n",
    "    data_test, test_labeles, pose_test = get_batch(51, data_dir)\n",
    "    output = model.evaluate(sess, data_test, test_labels, pose_test)\n",
    "    saver = tf.train.Saver()\n",
    "    model_path = saver.save(sess, \"saved_models/encoder_pose.ckpt\")\n",
    "    print(\"Model saved in %s\" % model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tmp = other[1240]\n",
    "print (tmp.shape)\n",
    "plt.imshow(tmp/255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = test_labels[3102]\n",
    "print (tmp.shape)\n",
    "plt.imshow(tmp/255)\n",
    "plt.show()\n",
    "print (pose_test[451][0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
