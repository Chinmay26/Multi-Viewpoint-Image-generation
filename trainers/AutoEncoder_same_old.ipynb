{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import misc\n",
    "from scipy import ndimage\n",
    "import os\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "loading done\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "print \"loading data\"\n",
    "#iterate over directory and get all png images\\n\n",
    "imageset = np.empty((7704,64,64,3), dtype='float32')\n",
    "\n",
    "#There are 7704 images in the dataset.\n",
    "#214 folders. Each having 36 images.\n",
    "rootdir = '/home/chsarath/kaushal_project/mug/models/3dw'\n",
    "cnt = 0\n",
    "total_cnt = 0\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        filepath = subdir + os.sep + file\n",
    "        if filepath.endswith('.png'):\n",
    "            if cnt == 36:\n",
    "                cnt = 0\n",
    "                total_cnt += 1\n",
    "            cnt += 1\n",
    "            seq_number = int(filepath.split('-')[-1].split('.')[0])\n",
    "            \n",
    "            imageset[total_cnt*36 + seq_number] = misc.imread(filepath).astype(np.float32)\n",
    "            \n",
    "print 'loading done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a2a1e8d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#this part is to visulize image\n",
    "tmp = imageset[69+65]\n",
    "print tmp.shape\n",
    "plt.imshow(tmp/255)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First 170 folders. 170*36 = 6120 images would be used for training\n",
    "# rest 46 folders would be used for testing\n",
    "\n",
    "\n",
    "labels = np.array(imageset)\n",
    "\n",
    "for cnt in range(216):\n",
    "    labels[cnt*36:(cnt+1)*36] = np.roll(imageset[cnt*36:(cnt+1)*36], 1, axis=0)\n",
    "\n",
    "imageset, labels = shuffle(imageset, labels, random_state=0)\n",
    "\n",
    "data_train = np.array(imageset[:6120])\n",
    "data_test = np.array(imageset[6120:])\n",
    "\n",
    "\n",
    "#This code will generate labels for the dataset\n",
    "\n",
    "# For current image label is the next image (image with 10 degree rotation)\n",
    "# For last image in the set (36th image) label would be first image\n",
    "\n",
    "train_labels = np.array(labels[:6120])\n",
    "test_labels = np.array(labels[6120:])\n",
    "\n",
    "# #Comment here for autoencoder\n",
    "# for cnt in range(170):\n",
    "#     train_labels[cnt*36:(cnt+1)*36] = np.roll(data_train[cnt*36:(cnt+1)*36], 1, axis=0)\n",
    "\n",
    "# for cnt in range(46):\n",
    "#     test_labels[cnt*36:(cnt+1)*36] = np.roll(data_test[cnt*36:(cnt+1)*36], 1, axis=0)\n",
    "# # comment ends for same image autoencoder\n",
    "\n",
    "#tmp = data_test[600]\n",
    "\n",
    "#Hidden viewpoint block is generated here.\n",
    "# For now it is same for all images. 10 degree angle change\n",
    "# it will change afterwards\n",
    "'''\n",
    "view_1d = np.zeros(36)\n",
    "view_1d[1] = 1\n",
    "view = np.broadcast_to(view_1d,(7776,8,8,36))\n",
    "view_train = view[:6120]\n",
    "view_test = view[6120:]\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "tmp = train_labels[223][...,::-1]\n",
    "tmp1 = data_train[223][...,::-1]\n",
    "\n",
    "\n",
    "plt.imshow(tmp/255)\n",
    "plt.show()\n",
    "plt.imshow(tmp1/255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#normalize data\n",
    "\n",
    "\n",
    "data_train *= 2\n",
    "data_train /= 255\n",
    "data_train -= 1\n",
    "\n",
    "data_test *= 2\n",
    "data_test /= 255\n",
    "data_test -= 1\n",
    "\n",
    "\n",
    "train_labels *= 2\n",
    "train_labels /= 255\n",
    "train_labels -= 1\n",
    "\n",
    "test_labels *= 2\n",
    "test_labels /= 255\n",
    "test_labels -= 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "#to Reset Tensor Flow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#defination of my layers\n",
    "\n",
    "def conv2d(input, kernel_size, stride, num_filter):\n",
    "    stride_shape = [1, stride, stride, 1]\n",
    "    filter_shape = [kernel_size, kernel_size, input.get_shape()[3], num_filter]\n",
    "\n",
    "    W = tf.get_variable('w', filter_shape, tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "    b = tf.get_variable('b', [1, 1, 1, num_filter], initializer=tf.constant_initializer(0.0))\n",
    "    return tf.nn.conv2d(input, W, stride_shape, padding='SAME') + b\n",
    "\n",
    "def max_pool(input, kernel_size, stride):\n",
    "    ksize = [1, kernel_size, kernel_size, 1]\n",
    "    strides = [1, stride, stride, 1]\n",
    "    return tf.nn.max_pool(input, ksize=ksize, strides=strides, padding='SAME')\n",
    "\n",
    "def deconv2d(input, kernel_size, stride, num_filter):\n",
    "    filter_shape = [kernel_size, kernel_size, num_filter, input.get_shape()[3]]\n",
    "    # tf.constant([input.get_shape()[0], input.get_shape()[1]*2, input.get_shape()[1]*2, num_filter], tf.int32)\n",
    "    input_dim = input.get_shape().as_list()\n",
    "    batch_size = input_dim[0]\n",
    "    w = input_dim[1]\n",
    "    out_shape = tf.stack([batch_size, w*2, w*2, num_filter])    \n",
    "\n",
    "    stride_shape = [1, stride, stride, 1]\n",
    "    W = tf.get_variable('w', filter_shape, tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "    \n",
    "    return tf.nn.conv2d_transpose(input, W, out_shape, stride_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Network Parameters\n",
    "\n",
    "#Encoder\n",
    "# input is 64 * 64 * 3 \n",
    "# batch_size is 72\n",
    "\n",
    "\n",
    "# tf Graph input (only pictures)\n",
    "\n",
    "inputs_ = tf.placeholder(tf.float32, (36, 64,64,3), name=\"input\")\n",
    "targets_ = tf.placeholder(tf.float32, (36, 64,64,3), name=\"target\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Building the encoder\n",
    "#Layer Architecture\n",
    "# Encoder will have Conv + relu + Max pool + Conv + relu  + Max pool + Conv + relu  + Max pool\n",
    "# After 3 Convolution ,we will have a latent space\n",
    "\n",
    "with tf.variable_scope('conv1'):\n",
    "    conv1 = conv2d(inputs_, 3, 2, 16)\n",
    "    tanh1 = tf.nn.relu(conv1)\n",
    "    #pool1 = max_pool(tanh1, 3, 2)\n",
    "\n",
    "# Size of pool1 would be 32*32*32\n",
    "\n",
    "with tf.variable_scope('conv2'):\n",
    "    conv2 = conv2d(tanh1, 3, 2, 32)\n",
    "    tanh2 = tf.nn.relu(conv2)\n",
    "    #pool2 = max_pool(tanh2, 3, 2)\n",
    "\n",
    "# # Size of pool2 would be 16*16*16\n",
    "\n",
    "with tf.variable_scope('conv3'):\n",
    "    conv3 = conv2d(tanh2, 3, 2, 64)\n",
    "    tanh3 = tf.nn.relu(conv3)\n",
    "    #pool3 = max_pool(tanh3, 3, 2)\n",
    "\n",
    "# # Latent space is 8*8*8\n",
    "# print pool3.get_shape().as_list()\n",
    "# #Building the decoder\n",
    "\n",
    "with tf.variable_scope('deconv1'):\n",
    "    deconv1 = deconv2d(tanh3, 3, 2, 32)\n",
    "    tanh4 = tf.nn.relu(deconv1)\n",
    "\n",
    "print tanh4.get_shape().as_list()\n",
    "with tf.variable_scope('deconv2'):\n",
    "    deconv2 = deconv2d(tanh4, 3, 2, 16)\n",
    "    tanh5 = tf.nn.relu(deconv2)\n",
    "print tanh5.get_shape().as_list()\n",
    "\n",
    "with tf.variable_scope('deconv3'):\n",
    "    deconv3 = deconv2d(tanh5, 3, 2, 3)\n",
    "    tanh6 = tf.nn.tanh(deconv3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#calculate loss\n",
    "loss_op = tf.reduce_mean(abs(tanh6 - targets_))\n",
    "\n",
    "#Optimizer\n",
    "global_step = tf.Variable(0,trainable=False)\n",
    "lr = tf.train.exponential_decay(5e-4, global_step, 1000, 0.96, staircase=True)\n",
    "optimizer = tf.train.AdamOptimizer(lr)\n",
    "train_op = optimizer.minimize(loss=loss_op)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Training Parameters\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 36\n",
    "total_images = 6120\n",
    "\n",
    "display_step = 1000\n",
    "examples_to_show = 10\n",
    "\n",
    "\n",
    "for e in range(epochs):\n",
    "    for ii in range(total_images // batch_size):\n",
    "        batch = data_train[ii*batch_size : (ii+1)*batch_size]\n",
    "        batch_labels = train_labels[ii*batch_size : (ii+1)*batch_size]\n",
    "        feed_dict = {inputs_: batch, targets_: batch_labels}\n",
    "\n",
    "        fetches = [train_op, loss_op]\n",
    "        _, loss = sess.run(fetches, feed_dict=feed_dict)\n",
    "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "            \"Training loss: {:.4f}\".format(loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#compare test image \n",
    "\n",
    "tmp = imageset[6120+71][...,::-1]\n",
    "print tmp.shape\n",
    "plt.imshow(tmp/255)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "feed_dict = {inputs_: data_test[:36], targets_: test_labels[:36]}\n",
    "\n",
    "fetches = [tanh6, loss_op]\n",
    "out, loss = sess.run(fetches, feed_dict=feed_dict)\n",
    "print loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "other = np.array(out)\n",
    "\n",
    "print other.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_labels_copy = test_labels[0:72]\n",
    "\n",
    "# test_labels_copy *= max_labels\n",
    "# test_labels_copy += mean_labels\n",
    "\n",
    "# tmp = test_labels_copy[36]\n",
    "\n",
    "# tmp = np.where(tmp>255,255,tmp)\n",
    "# tmp = np.where(tmp<0,0,tmp)\n",
    "# tmp = tmp\n",
    "# plt.imshow(tmp)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "out += 1\n",
    "out *=  255\n",
    "out /= 2\n",
    "\n",
    "# print np.amax(out)\n",
    "# print np.amin(out)\n",
    "# out = np.where(out>255,255,out)\n",
    "# out = np.where(out<0,0,out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "tmp = out[12]\n",
    "print tmp.shape\n",
    "plt.imshow(tmp/255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_labels += 1\n",
    "test_labels *=  255\n",
    "test_labels /= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = test_labels[12]\n",
    "plt.imshow(tmp/255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
